{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1418bc9",
   "metadata": {},
   "source": [
    "# 4 Modeling: Breast Cancer Gene Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd70d1e",
   "metadata": {},
   "source": [
    "## 4.1 Contents\n",
    "* [4 Modeling](#4_modeling)\n",
    "    * [4.1 Contents](#4.1_contents)\n",
    "    * [4.2 Introduction](#4.2_intro)\n",
    "    * [4.3 Imports](#4.3_imports)\n",
    "    * [4.4 Loading the Data](#4.4_loading)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111ddbdd",
   "metadata": {},
   "source": [
    "## 4.2 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d978cec",
   "metadata": {},
   "source": [
    "## 4.3 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1977707e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Libraries\n"
     ]
    }
   ],
   "source": [
    "# data manipulation and math\n",
    "#\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "#\n",
    "# plotting and visualization\n",
    "#\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "import seaborn as sns\n",
    "#\n",
    "# modeling\n",
    "#\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "#from sklearn.metrics import plot_precision_recall_curve\n",
    "#\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "\n",
    "#classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "import pickle\n",
    "import time \n",
    "print(\"Loaded Libraries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74dd27e",
   "metadata": {},
   "source": [
    "## 4.4 Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78052b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the NumPy arrays from the pickle files\n",
    "with open(r'C:\\Users\\leann\\OneDrive\\Desktop\\SPRINGBOARD\\capstone 2\\exports\\X_train_190.pkl', 'rb') as file:\n",
    "    X_train_190 = pickle.load(file)\n",
    "    \n",
    "with open(r'C:\\Users\\leann\\OneDrive\\Desktop\\SPRINGBOARD\\capstone 2\\exports\\X_test_190.pkl', 'rb') as file:\n",
    "    X_test_190 = pickle.load(file)  \n",
    "    \n",
    "with open(r'C:\\Users\\leann\\OneDrive\\Desktop\\SPRINGBOARD\\capstone 2\\exports\\X_train_360.pkl', 'rb') as file:\n",
    "    X_train_360 = pickle.load(file)  \n",
    "    \n",
    "with open(r'C:\\Users\\leann\\OneDrive\\Desktop\\SPRINGBOARD\\capstone 2\\exports\\X_test_360.pkl', 'rb') as file:\n",
    "    X_test_360 = pickle.load(file) \n",
    "    \n",
    "with open(r'C:\\Users\\leann\\OneDrive\\Desktop\\SPRINGBOARD\\capstone 2\\exports\\X_train_full.pkl', 'rb') as file:\n",
    "    X_train_full = pickle.load(file) \n",
    "\n",
    "with open(r'C:\\Users\\leann\\OneDrive\\Desktop\\SPRINGBOARD\\capstone 2\\exports\\X_test_full.pkl', 'rb') as file:\n",
    "    X_test_full = pickle.load(file) \n",
    "    \n",
    "with open(r'C:\\Users\\leann\\OneDrive\\Desktop\\SPRINGBOARD\\capstone 2\\exports\\y_train.pkl', 'rb') as file:\n",
    "    y_train = pickle.load(file) \n",
    "    \n",
    "with open(r'C:\\Users\\leann\\OneDrive\\Desktop\\SPRINGBOARD\\capstone 2\\exports\\y_test.pkl', 'rb') as file:\n",
    "    y_test = pickle.load(file) \n",
    "    \n",
    "# importing using parquet to preserve data types - this is the full dataset used to create the splits above\n",
    "\n",
    "num_data=pd.read_parquet(r'C:\\Users\\leann\\OneDrive\\Desktop\\SPRINGBOARD\\capstone 2\\num_data2.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c82b452",
   "metadata": {},
   "source": [
    "We have an imbalanced problem here: the class we are interested in (1, the patients who died of disease) are the minority class. As we saw in the EDA section, 33% of our data belongs to class 1.\n",
    "\n",
    "As a solution to this, I am going to do resampling via the Synthetic Minority Over-sampling Technique (SMOTE), which synthesizes new data from within the minority class. It's an oversampling technique that should minimize overfitting. I also am going to try undersamping with NearMiss, and see how it compares. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b19a280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into X and y\n",
    "\n",
    "X=num_data.drop('outcome', axis=1)\n",
    "y=num_data['outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e21b91a",
   "metadata": {},
   "source": [
    "Do test train split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20af6abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd8c8af",
   "metadata": {},
   "source": [
    "<b> Oversampling </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4967f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Implement SMOTE:\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_os, y_train_os = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "525c5ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcomes:\n",
      " 1    50.0\n",
      "0    50.0\n",
      "Name: outcome, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Confirming that our classes are now balanced\n",
    "\n",
    "SMOTE_survival_counts = pd.Series(y_train_os).value_counts()\n",
    "print('Outcomes:\\n',100*SMOTE_survival_counts/len(y_train_os))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1655c8",
   "metadata": {},
   "source": [
    "<b> Undersampling </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c0b5afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nm = NearMiss(version=1)\n",
    "X_train_us, y_train_us = nm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57921505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcomes:\n",
      " 0    50.0\n",
      "1    50.0\n",
      "Name: outcome, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Confirming that our classes are now balanced\n",
    "\n",
    "undersampling_survival_counts = pd.Series(y_train_us).value_counts()\n",
    "print('Outcomes:\\n',100*undersampling_survival_counts/len(y_train_us))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c23d5b",
   "metadata": {},
   "source": [
    "I want to easily be able to compare all of the results, so I will append them to an empty I'm creating now dataframe, results_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feec27c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Model', 'Mean CV F1 Score', 'F1 Pos Class Score'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fff497",
   "metadata": {},
   "source": [
    "### Logistic Regression Base Model (no resampling)\n",
    "\n",
    "This is our untuned logistic regression model on the data set with no resampling and no PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5c92a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40837696 0.42391304 0.39130435 0.46601942 0.41489362]\n",
      "Mean CV F1 score for the positive class: 0.42 (+/- 0.05)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72       320\n",
      "           1       0.45      0.50      0.47       156\n",
      "\n",
      "    accuracy                           0.64       476\n",
      "   macro avg       0.60      0.60      0.60       476\n",
      "weighted avg       0.65      0.64      0.64       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(solver = 'newton-cg', max_iter = 500) \n",
    "lr_model.fit(X_train,y_train)\n",
    "y_predict_test = lr_model.predict(X_test)\n",
    "\n",
    "scores = cross_val_score(lr_model, X_train, y_train, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "\n",
    "print(\"Mean CV F1 score for the positive class: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff9aa6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[225  95]\n",
      " [ 78  78]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predict_test)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf475901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Mean CV F1 Score  F1 Pos Class Score\n",
       "0  Logistic Regression Base Model              0.42                0.47"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results to the DataFrame containing all of the results:\n",
    "new_results = pd.DataFrame([{'Model': 'Logistic Regression Base Model', 'Mean CV F1 Score': round(scores.mean(),2), 'F1 Pos Class Score':0.47}])\n",
    "results_df = pd.concat([results_df, new_results], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfe7610",
   "metadata": {},
   "source": [
    "### Logistic Regression for Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf78696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47435897 0.53211009 0.74879227 0.84513274 0.8590604 ]\n",
      "Mean CV F1 score for the positive class: 0.69 (+/- 0.32)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.72       320\n",
      "           1       0.45      0.51      0.47       156\n",
      "\n",
      "    accuracy                           0.63       476\n",
      "   macro avg       0.59      0.60      0.60       476\n",
      "weighted avg       0.65      0.63      0.64       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model_os = LogisticRegression(solver = 'newton-cg', max_iter = 500) \n",
    "lr_model_os.fit(X_train_os, y_train_os)\n",
    "y_predict_test_os = lr_model_os.predict(X_test)\n",
    "\n",
    "scores = cross_val_score(lr_model_os, X_train_os, y_train_os, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "\n",
    "print(\"Mean CV F1 score for the positive class: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print(classification_report(y_test, y_predict_test_os))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca1c0636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[222  98]\n",
      " [ 77  79]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predict_test_os)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc3f64",
   "metadata": {},
   "source": [
    "This is almost the same as the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71e71ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model  Mean CV F1 Score  F1 Pos Class Score\n",
       "0         Logistic Regression Base Model              0.42                0.47\n",
       "1  Logistic Regression Oversampled Model              0.69                0.47"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results to the DataFrame containing all of the results:\n",
    "new_results = pd.DataFrame([{'Model': 'Logistic Regression Oversampled Model', 'Mean CV F1 Score': round(scores.mean(),2), 'F1 Pos Class Score':0.47}])\n",
    "results_df = pd.concat([results_df, new_results], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af07b71",
   "metadata": {},
   "source": [
    "### Logistic Regression for Undersampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d59f99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75138122 0.69512195 0.73298429 0.7357513  0.70422535]\n",
      "Mean CV F1 score for the positive class: 0.72 (+/- 0.04)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.50      0.62       320\n",
      "           1       0.42      0.74      0.53       156\n",
      "\n",
      "    accuracy                           0.58       476\n",
      "   macro avg       0.61      0.62      0.58       476\n",
      "weighted avg       0.67      0.58      0.59       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model_us = LogisticRegression(solver = 'newton-cg', max_iter = 500) \n",
    "lr_model_us.fit(X_train_us, y_train_us)\n",
    "y_predict_test_us = lr_model_us.predict(X_test)\n",
    "\n",
    "scores = cross_val_score(lr_model_us, X_train_us, y_train_us, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "\n",
    "print(\"Mean CV F1 score for the positive class: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print(classification_report(y_test, y_predict_test_us))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3de7bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[161 159]\n",
      " [ 41 115]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predict_test_us)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a1ea99",
   "metadata": {},
   "source": [
    "The undersampled data set actually performs better at correctly identifying cancer deaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b418d280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Undersampled Model</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Model  Mean CV F1 Score  \\\n",
       "0          Logistic Regression Base Model              0.42   \n",
       "1   Logistic Regression Oversampled Model              0.69   \n",
       "2  Logistic Regression Undersampled Model              0.72   \n",
       "\n",
       "   F1 Pos Class Score  \n",
       "0                0.47  \n",
       "1                0.47  \n",
       "2                0.53  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results to the DataFrame containing all of the results:\n",
    "new_results = pd.DataFrame([{'Model': 'Logistic Regression Undersampled Model', 'Mean CV F1 Score': round(scores.mean(),2), 'F1 Pos Class Score':0.53}])\n",
    "results_df = pd.concat([results_df, new_results], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c61817f",
   "metadata": {},
   "source": [
    "### Logistic Regression - Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58ff474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to come up with cross validation scores: QUESTION - is this necessary or can I just use cross_val_score()?\n",
    "def cv_score(clf, x, y, score_func = f1_score):\n",
    "    result = 0\n",
    "    nfold = 5\n",
    "    x.reset_index(drop = True, inplace = True)\n",
    "    y.index = x.index\n",
    "    for train, test in KFold(nfold, shuffle = True,\n",
    "                             random_state = 42).split(x):\n",
    "        clf.fit(x.loc[train, :], y[train])\n",
    "        result += score_func(clf.predict(x.loc[test, :]), y[test])\n",
    "    return result / nfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01b36465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X_train_os and y_train to pandas DataFrames\n",
    "X_train_os_df = pd.DataFrame(X_train_os)\n",
    "y_train_os_df = pd.Series(y_train_os)\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "y_test_df=pd.Series(y_test)\n",
    "\n",
    "# Convert X_train_us to pandas DataFrame\n",
    "X_train_us_df = pd.DataFrame(X_train_us)\n",
    "y_train_us_df = pd.DataFrame(y_train_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dbea59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for oversampled data: {'C': 0.1, 'penalty': 'l1'}\n",
      "Accuracy score for oversampled data: 0.7247556744079577\n",
      "\n",
      "Best hyperparameters for undersampled data: {'C': 0.001, 'penalty': 'l2'}\n",
      "F1 score for undersampled data: 0.7697456598473039\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning using grid search\n",
    "\n",
    "params={\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':[0.001, 0.1, 1, 10, 100],\n",
    "    }\n",
    "\n",
    "# instantiate the model\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#  do GridSearchCV\n",
    "grid_search= GridSearchCV(estimator=logreg,param_grid=params,cv=5, scoring='f1', n_jobs=-1)\n",
    "\n",
    "# Oversampled Data\n",
    "grid_search.fit(X_train_os,y_train_os)\n",
    "\n",
    "# print best hyperparameters and F1 score\n",
    "print(\"Best hyperparameters for oversampled data:\", grid_search.best_params_)\n",
    "print(\"Accuracy score for oversampled data:\", grid_search.best_score_)\n",
    "\n",
    "# Undersampled data\n",
    "grid_search.fit(X_train_us,y_train_us)\n",
    "\n",
    "# print best hyperparameters and F1 score\n",
    "print(\"\\nBest hyperparameters for undersampled data:\", grid_search.best_params_)\n",
    "print(\"F1 score for undersampled data:\", grid_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb998cb",
   "metadata": {},
   "source": [
    "### Logistic Regression with new hyperparameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88afb7ec",
   "metadata": {},
   "source": [
    "<b> Oversampled Data </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd885025",
   "metadata": {},
   "source": [
    "changing solver to 'liblinear' as it supports l1 penalty, and 'saga' got convergence errors with the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0f1e2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53250774 0.59235669 0.76683938 0.86896552 0.86310905]\n",
      "Mean CV F1 score for the positive class: 0.72 (+/- 0.28)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.72       320\n",
      "           1       0.45      0.51      0.47       156\n",
      "\n",
      "    accuracy                           0.63       476\n",
      "   macro avg       0.59      0.60      0.60       476\n",
      "weighted avg       0.65      0.63      0.64       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model_os_tuned = LogisticRegression(solver = 'liblinear', max_iter = 500, C=0.1, penalty='l1') \n",
    "lr_model_os_tuned.fit(X_train_os, y_train_os)\n",
    "y_predict_test_tuned_os = lr_model_os.predict(X_test)\n",
    "\n",
    "scores = cross_val_score(lr_model_os_tuned, X_train_os, y_train_os, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "\n",
    "print(\"Mean CV F1 score for the positive class: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print(classification_report(y_test, y_predict_test_tuned_os))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "270b2409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[222  98]\n",
      " [ 77  79]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predict_test_tuned_os)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1a6bf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Undersampled Model</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression Oversampled, Tuned</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Model  Mean CV F1 Score  \\\n",
       "0          Logistic Regression Base Model              0.42   \n",
       "1   Logistic Regression Oversampled Model              0.69   \n",
       "2  Logistic Regression Undersampled Model              0.72   \n",
       "3  Logistic Regression Oversampled, Tuned              0.72   \n",
       "\n",
       "   F1 Pos Class Score  \n",
       "0                0.47  \n",
       "1                0.47  \n",
       "2                0.53  \n",
       "3                0.47  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results to the DataFrame containing all of the results:\n",
    "new_results = pd.DataFrame([{'Model': 'Logistic Regression Oversampled, Tuned', 'Mean CV F1 Score': round(scores.mean(),2), 'F1 Pos Class Score':0.47}])\n",
    "results_df = pd.concat([results_df, new_results], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e685008",
   "metadata": {},
   "source": [
    "<b> Oversampled Data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "943bf2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8502994  0.71428571 0.77966102 0.75824176 0.7254902 ]\n",
      "Mean CV F1 score for the positive class: 0.77 (+/- 0.10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.50      0.62       320\n",
      "           1       0.42      0.74      0.53       156\n",
      "\n",
      "    accuracy                           0.58       476\n",
      "   macro avg       0.61      0.62      0.58       476\n",
      "weighted avg       0.67      0.58      0.59       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model_us_tuned = LogisticRegression(solver = 'newton-cg', max_iter = 500, C=0.001, penalty='l2') \n",
    "lr_model_us_tuned.fit(X_train_us, y_train_us)\n",
    "y_predict_test_tuned_us = lr_model_us.predict(X_test)\n",
    "\n",
    "scores = cross_val_score(lr_model_us_tuned, X_train_us, y_train_us, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "\n",
    "print(\"Mean CV F1 score for the positive class: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print(classification_report(y_test, y_predict_test_tuned_us))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65ad95ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[161 159]\n",
      " [ 41 115]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predict_test_tuned_us)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04ad2097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Undersampled Model</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression Oversampled, Tuned</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Model  Mean CV F1 Score  \\\n",
       "0           Logistic Regression Base Model              0.42   \n",
       "1    Logistic Regression Oversampled Model              0.69   \n",
       "2   Logistic Regression Undersampled Model              0.72   \n",
       "3   Logistic Regression Oversampled, Tuned              0.72   \n",
       "4  Logistic Regression Undersampled, Tuned              0.77   \n",
       "\n",
       "   F1 Pos Class Score  \n",
       "0                0.47  \n",
       "1                0.47  \n",
       "2                0.53  \n",
       "3                0.47  \n",
       "4                0.53  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results to the DataFrame containing all of the results:\n",
    "new_results = pd.DataFrame([{'Model': 'Logistic Regression Undersampled, Tuned', 'Mean CV F1 Score': round(scores.mean(),2), 'F1 Pos Class Score':0.53}])\n",
    "results_df = pd.concat([results_df, new_results], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6051e502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = {\n",
    "    'Logistic Regression Oversampled': LogisticRegression(solver = 'liblinear', max_iter = 500, C=0.1, penalty='l1'),\n",
    "    'Logistic Regression Undersampled': LogisticRegression(solver = 'newton-cg', max_iter = 500, C=0.001, penalty='l2'),\n",
    "}\n",
    "\n",
    "training_data = {\n",
    "    'Logistic Regression Oversampled': (X_train_os, y_train_os),\n",
    "    'Logistic Regression Undersampled': (X_train_us, y_train_us),\n",
    "}\n",
    "\n",
    "# Use the same test data for both models\n",
    "testing_data = X_test\n",
    "\n",
    "for name, model in models.items():\n",
    "    X_train_res, y_train_res = training_data[name]\n",
    "    model.fit(X_train_res, y_train_res) # Use the resampled y_train data\n",
    "    y_scores = model.predict_proba(testing_data)[:, 1]\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
    "    plt.plot(recall, precision, marker='.', label=name)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece73aab",
   "metadata": {},
   "source": [
    "# Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2b9fce",
   "metadata": {},
   "source": [
    "<b> Oversampled </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1873778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67283951 0.69538462 0.82539683 0.89371981 0.88674699]\n",
      "Mean CV F1 score for the positive class: 0.79 (+/- 0.19)\n",
      "Random Forest Model: Test data, Oversampled:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79       320\n",
      "           1       0.53      0.31      0.40       156\n",
      "\n",
      "    accuracy                           0.68       476\n",
      "   macro avg       0.63      0.59      0.59       476\n",
      "weighted avg       0.66      0.68      0.66       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "rfc_os = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rfc_os.fit(X_train_os, y_train_os)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_predict_test_os_rf = rfc_os.predict(X_test)\n",
    "\n",
    "\n",
    "scores = cross_val_score(rfc_os, X_train_os, y_train_os, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "\n",
    "print(\"Mean CV F1 score for the positive class: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "\n",
    "# Test classification report, all components: \n",
    "print('Random Forest Model: Test data, Oversampled:\\n',classification_report(y_test,y_predict_test_os_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51f67ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[277  43]\n",
      " [107  49]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predict_test_os_rf)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22239e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Undersampled Model</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression Oversampled, Tuned</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Model  Mean CV F1 Score  \\\n",
       "0           Logistic Regression Base Model              0.42   \n",
       "1    Logistic Regression Oversampled Model              0.69   \n",
       "2   Logistic Regression Undersampled Model              0.72   \n",
       "3   Logistic Regression Oversampled, Tuned              0.72   \n",
       "4  Logistic Regression Undersampled, Tuned              0.77   \n",
       "5               Random Forest, Oversampled              0.79   \n",
       "\n",
       "   F1 Pos Class Score  \n",
       "0                0.47  \n",
       "1                0.47  \n",
       "2                0.53  \n",
       "3                0.47  \n",
       "4                0.53  \n",
       "5                0.40  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results to the DataFrame containing all of the results:\n",
    "new_results = pd.DataFrame([{'Model': 'Random Forest, Oversampled', 'Mean CV F1 Score': round(scores.mean(),2), 'F1 Pos Class Score':0.40}])\n",
    "results_df = pd.concat([results_df, new_results], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa56fd",
   "metadata": {},
   "source": [
    "<b> Undersampled </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05737b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83950617 0.72839506 0.75       0.74509804 0.69194313]\n",
      "Mean CV F1 score for the positive class: 0.75 (+/- 0.10)\n",
      "Random Forest Model: Test data, Undersampled:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.45      0.57       320\n",
      "           1       0.39      0.72      0.51       156\n",
      "\n",
      "    accuracy                           0.54       476\n",
      "   macro avg       0.58      0.59      0.54       476\n",
      "weighted avg       0.65      0.54      0.55       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "rfc_us = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rfc_us.fit(X_train_us, y_train_us)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_predict_test_us_rf = rfc_us.predict(X_test)\n",
    "\n",
    "\n",
    "scores = cross_val_score(rfc_us, X_train_us, y_train_us, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "print(\"Mean CV F1 score for the positive class: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# Test classification report, all components: \n",
    "print('Random Forest Model: Test data, Undersampled:\\n',classification_report(y_test,y_predict_test_us_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c40bbbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[145 175]\n",
      " [ 43 113]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predict_test_us_rf)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8f3d9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Undersampled Model</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression Oversampled, Tuned</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Model  Mean CV F1 Score  \\\n",
       "0           Logistic Regression Base Model              0.42   \n",
       "1    Logistic Regression Oversampled Model              0.69   \n",
       "2   Logistic Regression Undersampled Model              0.72   \n",
       "3   Logistic Regression Oversampled, Tuned              0.72   \n",
       "4  Logistic Regression Undersampled, Tuned              0.77   \n",
       "5               Random Forest, Oversampled              0.79   \n",
       "6              Random Forest, Undersampled              0.75   \n",
       "\n",
       "   F1 Pos Class Score  \n",
       "0                0.47  \n",
       "1                0.47  \n",
       "2                0.53  \n",
       "3                0.47  \n",
       "4                0.53  \n",
       "5                0.40  \n",
       "6                0.51  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results to the DataFrame containing all of the results:\n",
    "new_results = pd.DataFrame([{'Model': 'Random Forest, Undersampled', 'Mean CV F1 Score': round(scores.mean(),2), 'F1 Pos Class Score':0.51}])\n",
    "results_df = pd.concat([results_df, new_results], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efdc9c2",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9fae2d",
   "metadata": {},
   "source": [
    "<b> Oversampled </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d8a9ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rfc_os = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rfc_os, param_grid = param_grid, \n",
    "                           cv = 5, scoring='f1', n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_os, y_train_os)\n",
    "\n",
    "# Get the best parameters\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67066e4f",
   "metadata": {},
   "source": [
    "<b> Tuning the model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b03a285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73802817 0.77746479 0.81841432 0.88056206 0.8591224 ]\n",
      "Mean CV F1 score for the positive class: 0.81 (+/- 0.10)\n",
      "Random Forest Model: Test data, Oversampled:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77       320\n",
      "           1       0.51      0.46      0.49       156\n",
      "\n",
      "    accuracy                           0.68       476\n",
      "   macro avg       0.63      0.62      0.63       476\n",
      "weighted avg       0.67      0.68      0.68       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "rfc_os_tuned = RandomForestClassifier(n_estimators=300, max_depth=10,min_samples_leaf=2,min_samples_split=2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rfc_os_tuned.fit(X_train_os, y_train_os)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_predict_test_os_rf_tuned = rfc_os_tuned.predict(X_test)\n",
    "\n",
    "\n",
    "scores = cross_val_score(rfc_os_tuned, X_train_os, y_train_os, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "\n",
    "print(\"Mean CV F1 score for the positive class: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "\n",
    "# Test classification report, all components: \n",
    "print('Random Forest Model: Test data, Oversampled:\\n',classification_report(y_test,y_predict_test_os_rf_tuned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a698e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[252  68]\n",
      " [ 84  72]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predict_test_os_rf_tuned)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24672b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Undersampled Model</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression Oversampled, Tuned</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest, Oversampled, Tuned</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Model  Mean CV F1 Score  \\\n",
       "0           Logistic Regression Base Model              0.42   \n",
       "1    Logistic Regression Oversampled Model              0.69   \n",
       "2   Logistic Regression Undersampled Model              0.72   \n",
       "3   Logistic Regression Oversampled, Tuned              0.72   \n",
       "4  Logistic Regression Undersampled, Tuned              0.77   \n",
       "5               Random Forest, Oversampled              0.79   \n",
       "6              Random Forest, Undersampled              0.75   \n",
       "7        Random Forest, Oversampled, Tuned              0.81   \n",
       "\n",
       "   F1 Pos Class Score  \n",
       "0                0.47  \n",
       "1                0.47  \n",
       "2                0.53  \n",
       "3                0.47  \n",
       "4                0.53  \n",
       "5                0.40  \n",
       "6                0.51  \n",
       "7                0.49  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results to the DataFrame containing all of the results:\n",
    "new_results = pd.DataFrame([{'Model': 'Random Forest, Oversampled, Tuned', 'Mean CV F1 Score': round(scores.mean(),2), 'F1 Pos Class Score':0.49}])\n",
    "results_df = pd.concat([results_df, new_results], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0867d1e3",
   "metadata": {},
   "source": [
    "<b> Undersampled, Tuned </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1290a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rfc_us = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rfc_us, param_grid = param_grid, \n",
    "                           cv = 5, scoring='f1', n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_us, y_train_us)\n",
    "\n",
    "# Get the best parameters\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f09fc0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84146341 0.73619632 0.80446927 0.75247525 0.71497585]\n",
      "Mean CV F1 score for the positive class: 0.77 (+/- 0.09)\n",
      "Random Forest Model: Test data, Oversampled:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.47      0.59       320\n",
      "           1       0.41      0.74      0.52       156\n",
      "\n",
      "    accuracy                           0.56       476\n",
      "   macro avg       0.60      0.61      0.56       476\n",
      "weighted avg       0.66      0.56      0.57       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "rfc_us_tuned = RandomForestClassifier(n_estimators=300, max_depth=10,min_samples_leaf=4,min_samples_split=2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rfc_us_tuned.fit(X_train_us, y_train_us)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_predict_test_us_rf_tuned = rfc_us_tuned.predict(X_test)\n",
    "\n",
    "\n",
    "scores = cross_val_score(rfc_us_tuned, X_train_us, y_train_us, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "\n",
    "print(\"Mean CV F1 score for the positive class: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "\n",
    "# Test classification report, all components: \n",
    "print('Random Forest Model: Test data, Oversampled:\\n',classification_report(y_test,y_predict_test_us_rf_tuned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "393ad911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[150 170]\n",
      " [ 40 116]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predict_test_us_rf_tuned)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13ecc7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Undersampled Model</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression Oversampled, Tuned</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest, Oversampled, Tuned</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest, Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Model  Mean CV F1 Score  \\\n",
       "0           Logistic Regression Base Model              0.42   \n",
       "1    Logistic Regression Oversampled Model              0.69   \n",
       "2   Logistic Regression Undersampled Model              0.72   \n",
       "3   Logistic Regression Oversampled, Tuned              0.72   \n",
       "4  Logistic Regression Undersampled, Tuned              0.77   \n",
       "5               Random Forest, Oversampled              0.79   \n",
       "6              Random Forest, Undersampled              0.75   \n",
       "7        Random Forest, Oversampled, Tuned              0.81   \n",
       "8       Random Forest, Undersampled, Tuned              0.77   \n",
       "\n",
       "   F1 Pos Class Score  \n",
       "0                0.47  \n",
       "1                0.47  \n",
       "2                0.53  \n",
       "3                0.47  \n",
       "4                0.53  \n",
       "5                0.40  \n",
       "6                0.51  \n",
       "7                0.49  \n",
       "8                0.52  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results to the DataFrame containing all of the results:\n",
    "new_results = pd.DataFrame([{'Model': 'Random Forest, Undersampled, Tuned', 'Mean CV F1 Score': round(scores.mean(),2), 'F1 Pos Class Score':0.52}])\n",
    "results_df = pd.concat([results_df, new_results], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6155f54",
   "metadata": {},
   "source": [
    "# XG Boost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1acf24f",
   "metadata": {},
   "source": [
    "<b> Oversampled model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c8e2f80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60450161 0.72072072 0.81794195 0.89719626 0.89929742]\n",
      "Mean CV F1 score for the positive class: 0.79 (+/- 0.23)\n",
      "Test Classification Report, XG Boost, Oversampled               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79       320\n",
      "           1       0.55      0.43      0.48       156\n",
      "\n",
      "    accuracy                           0.70       476\n",
      "   macro avg       0.65      0.63      0.64       476\n",
      "weighted avg       0.69      0.70      0.69       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "xgboost_model_os = XGBClassifier()\n",
    "xgboost_model_os.fit(X_train_os, y_train_os)\n",
    "\n",
    "# make predictions for test data\n",
    "xgboost_y_pred_os = xgboost_model_os.predict(X_test)\n",
    "predictions = [round(value) for value in xgboost_y_pred_os]\n",
    "\n",
    "\n",
    "scores = cross_val_score(xgboost_model_os, X_train_os, y_train_os, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "\n",
    "print(\"Mean CV F1 score for the positive class: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print('Test Classification Report, XG Boost, Oversampled',classification_report(y_test, xgboost_y_pred_os))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f56087bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[266  54]\n",
      " [ 89  67]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, xgboost_y_pred_os)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "062ed4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Undersampled Model</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression Oversampled, Tuned</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest, Oversampled, Tuned</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest, Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XG Boost, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Model  Mean CV F1 Score  \\\n",
       "0           Logistic Regression Base Model              0.42   \n",
       "1    Logistic Regression Oversampled Model              0.69   \n",
       "2   Logistic Regression Undersampled Model              0.72   \n",
       "3   Logistic Regression Oversampled, Tuned              0.72   \n",
       "4  Logistic Regression Undersampled, Tuned              0.77   \n",
       "5               Random Forest, Oversampled              0.79   \n",
       "6              Random Forest, Undersampled              0.75   \n",
       "7        Random Forest, Oversampled, Tuned              0.81   \n",
       "8       Random Forest, Undersampled, Tuned              0.77   \n",
       "9                    XG Boost, Oversampled              0.79   \n",
       "\n",
       "   F1 Pos Class Score  \n",
       "0                0.47  \n",
       "1                0.47  \n",
       "2                0.53  \n",
       "3                0.47  \n",
       "4                0.53  \n",
       "5                0.40  \n",
       "6                0.51  \n",
       "7                0.49  \n",
       "8                0.52  \n",
       "9                0.48  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results to the DataFrame containing all of the results:\n",
    "new_results = pd.DataFrame([{'Model': 'XG Boost, Oversampled', 'Mean CV F1 Score': round(scores.mean(),2), 'F1 Pos Class Score':0.48}])\n",
    "results_df = pd.concat([results_df, new_results], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d7719d",
   "metadata": {},
   "source": [
    "<b>Undersampled Model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39570374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82840237 0.72392638 0.74193548 0.75126904 0.71428571]\n",
      "Mean CV F1 score for the positive class: 0.75 (+/- 0.08)\n",
      "Test Classification Report, XG Boost, Undersampled               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.49      0.61       320\n",
      "           1       0.43      0.77      0.55       156\n",
      "\n",
      "    accuracy                           0.58       476\n",
      "   macro avg       0.62      0.63      0.58       476\n",
      "weighted avg       0.69      0.58      0.59       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "xgboost_model_us = XGBClassifier()\n",
    "xgboost_model_us.fit(X_train_us, y_train_us)\n",
    "\n",
    "# make predictions for test data\n",
    "xgboost_y_pred_us = xgboost_model_us.predict(X_test)\n",
    "predictions = [round(value) for value in xgboost_y_pred_us]\n",
    "\n",
    "\n",
    "scores = cross_val_score(xgboost_model_us, X_train_us, y_train_us, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "\n",
    "print(\"Mean CV F1 score for the positive class: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print('Test Classification Report, XG Boost, Undersampled',classification_report(y_test, xgboost_y_pred_us))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6bec5d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[158 162]\n",
      " [ 36 120]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, xgboost_y_pred_us)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9819cb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Undersampled Model</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression Oversampled, Tuned</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest, Oversampled, Tuned</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest, Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XG Boost, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XG Boost, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Model  Mean CV F1 Score  \\\n",
       "0            Logistic Regression Base Model              0.42   \n",
       "1     Logistic Regression Oversampled Model              0.69   \n",
       "2    Logistic Regression Undersampled Model              0.72   \n",
       "3    Logistic Regression Oversampled, Tuned              0.72   \n",
       "4   Logistic Regression Undersampled, Tuned              0.77   \n",
       "5                Random Forest, Oversampled              0.79   \n",
       "6               Random Forest, Undersampled              0.75   \n",
       "7         Random Forest, Oversampled, Tuned              0.81   \n",
       "8        Random Forest, Undersampled, Tuned              0.77   \n",
       "9                     XG Boost, Oversampled              0.79   \n",
       "10                   XG Boost, Undersampled              0.75   \n",
       "\n",
       "    F1 Pos Class Score  \n",
       "0                 0.47  \n",
       "1                 0.47  \n",
       "2                 0.53  \n",
       "3                 0.47  \n",
       "4                 0.53  \n",
       "5                 0.40  \n",
       "6                 0.51  \n",
       "7                 0.49  \n",
       "8                 0.52  \n",
       "9                 0.48  \n",
       "10                0.55  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results to the DataFrame containing all of the results:\n",
    "new_results = pd.DataFrame([{'Model': 'XG Boost, Undersampled', 'Mean CV F1 Score': round(scores.mean(),2), 'F1 Pos Class Score':0.55}])\n",
    "results_df = pd.concat([results_df, new_results], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c57f2",
   "metadata": {},
   "source": [
    "NOTE: This is the best one so far, as far as the F1 score goes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b73fb1",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784c2e06",
   "metadata": {},
   "source": [
    "<b> Oversampled </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0918a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "{'gamma': 0, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 200}\n",
      "0.7998481713612512\n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [2, 4, 6],\n",
    "    'min_child_weight': [1, 2, 3],\n",
    "    'learning_rate': [0.1, 0.01, 0.05],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize the classifier\n",
    "xgboost_model_os = XGBClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgboost_model_os, param_grid=grid, cv=5, scoring='f1', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_os, y_train_os)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c615b3bb",
   "metadata": {},
   "source": [
    "Apply the tuned hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30539800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60450161 0.72072072 0.81794195 0.89719626 0.89929742]\n",
      "Mean CV F1 score for the positive class: 0.79 (+/- 0.23)\n",
      "Test Classification Report, XG Boost, Oversampled, Tuned               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79       320\n",
      "           1       0.55      0.43      0.48       156\n",
      "\n",
      "    accuracy                           0.70       476\n",
      "   macro avg       0.65      0.63      0.64       476\n",
      "weighted avg       0.69      0.70      0.69       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "xgboost_model_os_tuned = XGBClassifier()\n",
    "xgboost_model_os_tuned.fit(X_train_os, y_train_os)\n",
    "\n",
    "# make predictions for test data\n",
    "xgboost_y_pred_os_tuned = xgboost_model_os_tuned.predict(X_test)\n",
    "predictions = [round(value) for value in xgboost_y_pred_os_tuned]\n",
    "\n",
    "\n",
    "scores = cross_val_score(xgboost_model_os_tuned, X_train_os, y_train_os, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "\n",
    "print(\"Mean CV F1 score for the positive class: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print('Test Classification Report, XG Boost, Oversampled, Tuned',classification_report(y_test, xgboost_y_pred_os_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9dc06436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[266  54]\n",
      " [ 89  67]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, xgboost_y_pred_os_tuned)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0dbbe01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Undersampled Model</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression Oversampled, Tuned</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest, Oversampled, Tuned</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest, Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XG Boost, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XG Boost, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XG Boost, Oversampled, Tuned</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Model  Mean CV F1 Score  \\\n",
       "0            Logistic Regression Base Model              0.42   \n",
       "1     Logistic Regression Oversampled Model              0.69   \n",
       "2    Logistic Regression Undersampled Model              0.72   \n",
       "3    Logistic Regression Oversampled, Tuned              0.72   \n",
       "4   Logistic Regression Undersampled, Tuned              0.77   \n",
       "5                Random Forest, Oversampled              0.79   \n",
       "6               Random Forest, Undersampled              0.75   \n",
       "7         Random Forest, Oversampled, Tuned              0.81   \n",
       "8        Random Forest, Undersampled, Tuned              0.77   \n",
       "9                     XG Boost, Oversampled              0.79   \n",
       "10                   XG Boost, Undersampled              0.75   \n",
       "11             XG Boost, Oversampled, Tuned              0.79   \n",
       "\n",
       "    F1 Pos Class Score  \n",
       "0                 0.47  \n",
       "1                 0.47  \n",
       "2                 0.53  \n",
       "3                 0.47  \n",
       "4                 0.53  \n",
       "5                 0.40  \n",
       "6                 0.51  \n",
       "7                 0.49  \n",
       "8                 0.52  \n",
       "9                 0.48  \n",
       "10                0.55  \n",
       "11                0.48  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results to the DataFrame containing all of the results:\n",
    "new_results = pd.DataFrame([{'Model': 'XG Boost, Oversampled, Tuned', 'Mean CV F1 Score': round(scores.mean(),2), 'F1 Pos Class Score':0.48}])\n",
    "results_df = pd.concat([results_df, new_results], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a35021",
   "metadata": {},
   "source": [
    "<b> Undersampled </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6abc189e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "{'gamma': 0, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 200}\n",
      "0.7621981384459869\n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [2, 4, 6],\n",
    "    'min_child_weight': [1, 2, 3],\n",
    "    'learning_rate': [0.1, 0.01, 0.05],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize the classifier\n",
    "xgboost_model_us_tuned = XGBClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgboost_model_us_tuned, param_grid=grid, cv=5, scoring='f1', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_us, y_train_us)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1579f8fb",
   "metadata": {},
   "source": [
    "Applying the tuned hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2508f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82142857 0.73493976 0.77777778 0.76530612 0.71153846]\n",
      "Mean CV F1 score for the positive class: 0.76 (+/- 0.08)\n",
      "Test Classification Report, XG Boost, Undersampled, Tuned               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.50      0.63       320\n",
      "           1       0.44      0.81      0.57       156\n",
      "\n",
      "    accuracy                           0.60       476\n",
      "   macro avg       0.64      0.65      0.60       476\n",
      "weighted avg       0.71      0.60      0.61       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "xgboost_model_us_tuned = XGBClassifier(gamma= 0, learning_rate=0.05, max_depth= 6, min_child_weight=1, n_estimators=200)\n",
    "xgboost_model_us_tuned.fit(X_train_us, y_train_us)\n",
    "\n",
    "# make predictions for test data\n",
    "xgboost_y_pred_us_tuned = xgboost_model_us_tuned.predict(X_test)\n",
    "predictions = [round(value) for value in xgboost_y_pred_us_tuned]\n",
    "\n",
    "\n",
    "scores = cross_val_score(xgboost_model_us_tuned, X_train_us, y_train_us, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "\n",
    "print(\"Mean CV F1 score for the positive class: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print('Test Classification Report, XG Boost, Undersampled, Tuned',classification_report(y_test, xgboost_y_pred_us_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8b4bd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[160 160]\n",
      " [ 30 126]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, xgboost_y_pred_us_tuned)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d654c764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Undersampled Model</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression Oversampled, Tuned</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest, Oversampled, Tuned</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest, Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XG Boost, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XG Boost, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XG Boost, Oversampled, Tuned</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XG Boost, Undersampled, Tuned</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Model  Mean CV F1 Score  \\\n",
       "0            Logistic Regression Base Model              0.42   \n",
       "1     Logistic Regression Oversampled Model              0.69   \n",
       "2    Logistic Regression Undersampled Model              0.72   \n",
       "3    Logistic Regression Oversampled, Tuned              0.72   \n",
       "4   Logistic Regression Undersampled, Tuned              0.77   \n",
       "5                Random Forest, Oversampled              0.79   \n",
       "6               Random Forest, Undersampled              0.75   \n",
       "7         Random Forest, Oversampled, Tuned              0.81   \n",
       "8        Random Forest, Undersampled, Tuned              0.77   \n",
       "9                     XG Boost, Oversampled              0.79   \n",
       "10                   XG Boost, Undersampled              0.75   \n",
       "11             XG Boost, Oversampled, Tuned              0.79   \n",
       "12            XG Boost, Undersampled, Tuned              0.76   \n",
       "\n",
       "    F1 Pos Class Score  \n",
       "0                 0.47  \n",
       "1                 0.47  \n",
       "2                 0.53  \n",
       "3                 0.47  \n",
       "4                 0.53  \n",
       "5                 0.40  \n",
       "6                 0.51  \n",
       "7                 0.49  \n",
       "8                 0.52  \n",
       "9                 0.48  \n",
       "10                0.55  \n",
       "11                0.48  \n",
       "12                0.57  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results to the DataFrame containing all of the results:\n",
    "new_results = pd.DataFrame([{'Model': 'XG Boost, Undersampled, Tuned', 'Mean CV F1 Score': round(scores.mean(),2), 'F1 Pos Class Score':0.57}])\n",
    "results_df = pd.concat([results_df, new_results], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4587a14",
   "metadata": {},
   "source": [
    "XG Boost, undersampled and tuned is the best so far!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dfd4e4",
   "metadata": {},
   "source": [
    "# LGBM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0501a0",
   "metadata": {},
   "source": [
    "<b> Oversampled </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68ec8f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61073826 0.64761905 0.82414698 0.90140845 0.89671362]\n",
      "Mean CV F1 score for the positive class: 0.78 (+/- 0.25)\n",
      "Test Classification Report, LGBM, Oversampled               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79       320\n",
      "           1       0.56      0.43      0.49       156\n",
      "\n",
      "    accuracy                           0.70       476\n",
      "   macro avg       0.65      0.63      0.64       476\n",
      "weighted avg       0.69      0.70      0.69       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using this method: https://machinelearningmastery.com/light-gradient-boosted-machine-lightgbm-ensemble/\n",
    "\n",
    "#create the model\n",
    "\n",
    "lgbm_model_os= LGBMClassifier()\n",
    "\n",
    "# fit the model\n",
    "lgbm_model_os.fit(X_train_os, y_train_os)\n",
    "\n",
    "# make predictions for test data\n",
    "lgbm_y_pred_os = lgbm_model_os.predict(X_test)\n",
    "predictions = [round(value) for value in lgbm_y_pred_os]\n",
    "\n",
    "\n",
    "scores = cross_val_score(lgbm_model_os, X_train_os, y_train_os, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "\n",
    "print(\"Mean CV F1 score for the positive class: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print('Test Classification Report, LGBM, Oversampled',classification_report(y_test, lgbm_y_pred_os))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1f07ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[267  53]\n",
      " [ 89  67]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, lgbm_y_pred_os)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "72fc361d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Undersampled Model</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression Oversampled, Tuned</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest, Oversampled, Tuned</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest, Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XG Boost, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XG Boost, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XG Boost, Oversampled, Tuned</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XG Boost, Undersampled, Tuned</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LGBM Model, Oversampled</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Model  Mean CV F1 Score  \\\n",
       "0            Logistic Regression Base Model              0.42   \n",
       "1     Logistic Regression Oversampled Model              0.69   \n",
       "2    Logistic Regression Undersampled Model              0.72   \n",
       "3    Logistic Regression Oversampled, Tuned              0.72   \n",
       "4   Logistic Regression Undersampled, Tuned              0.77   \n",
       "5                Random Forest, Oversampled              0.79   \n",
       "6               Random Forest, Undersampled              0.75   \n",
       "7         Random Forest, Oversampled, Tuned              0.81   \n",
       "8        Random Forest, Undersampled, Tuned              0.77   \n",
       "9                     XG Boost, Oversampled              0.79   \n",
       "10                   XG Boost, Undersampled              0.75   \n",
       "11             XG Boost, Oversampled, Tuned              0.79   \n",
       "12            XG Boost, Undersampled, Tuned              0.76   \n",
       "13                  LGBM Model, Oversampled              0.78   \n",
       "\n",
       "    F1 Pos Class Score  \n",
       "0                 0.47  \n",
       "1                 0.47  \n",
       "2                 0.53  \n",
       "3                 0.47  \n",
       "4                 0.53  \n",
       "5                 0.40  \n",
       "6                 0.51  \n",
       "7                 0.49  \n",
       "8                 0.52  \n",
       "9                 0.48  \n",
       "10                0.55  \n",
       "11                0.48  \n",
       "12                0.57  \n",
       "13                0.49  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results to the DataFrame containing all of the results:\n",
    "new_results = pd.DataFrame([{'Model': 'LGBM Model, Oversampled', 'Mean CV F1 Score': round(scores.mean(),2), 'F1 Pos Class Score':0.49}])\n",
    "results_df = pd.concat([results_df, new_results], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288c3737",
   "metadata": {},
   "source": [
    "<b> Undersampled </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e3019c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82352941 0.73619632 0.75280899 0.75376884 0.71962617]\n",
      "Mean CV F1 score for the positive class: 0.76 (+/- 0.07)\n",
      "Test Classification Report, LGBM, Undersampled               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.49      0.62       320\n",
      "           1       0.44      0.81      0.57       156\n",
      "\n",
      "    accuracy                           0.59       476\n",
      "   macro avg       0.64      0.65      0.59       476\n",
      "weighted avg       0.71      0.59      0.60       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create the model\n",
    "\n",
    "lgbm_model_us= LGBMClassifier()\n",
    "\n",
    "# fit the model\n",
    "lgbm_model_us.fit(X_train_us, y_train_us)\n",
    "\n",
    "# make predictions for test data\n",
    "lgbm_y_pred_us = lgbm_model_us.predict(X_test)\n",
    "predictions = [round(value) for value in lgbm_y_pred_us]\n",
    "\n",
    "\n",
    "scores = cross_val_score(lgbm_model_us, X_train_us, y_train_us, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "\n",
    "print(\"Mean CV F1 score for the positive class: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print('Test Classification Report, LGBM, Undersampled',classification_report(y_test, lgbm_y_pred_us))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9e10c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[157 163]\n",
      " [ 30 126]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, lgbm_y_pred_us)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e2dd652d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Undersampled Model</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression Oversampled, Tuned</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest, Oversampled, Tuned</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest, Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XG Boost, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XG Boost, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XG Boost, Oversampled, Tuned</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XG Boost, Undersampled, Tuned</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LGBM Model, Oversampled</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LGBM Model, Undersampled</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Model  Mean CV F1 Score  \\\n",
       "0            Logistic Regression Base Model              0.42   \n",
       "1     Logistic Regression Oversampled Model              0.69   \n",
       "2    Logistic Regression Undersampled Model              0.72   \n",
       "3    Logistic Regression Oversampled, Tuned              0.72   \n",
       "4   Logistic Regression Undersampled, Tuned              0.77   \n",
       "5                Random Forest, Oversampled              0.79   \n",
       "6               Random Forest, Undersampled              0.75   \n",
       "7         Random Forest, Oversampled, Tuned              0.81   \n",
       "8        Random Forest, Undersampled, Tuned              0.77   \n",
       "9                     XG Boost, Oversampled              0.79   \n",
       "10                   XG Boost, Undersampled              0.75   \n",
       "11             XG Boost, Oversampled, Tuned              0.79   \n",
       "12            XG Boost, Undersampled, Tuned              0.76   \n",
       "13                  LGBM Model, Oversampled              0.78   \n",
       "14                 LGBM Model, Undersampled              0.76   \n",
       "\n",
       "    F1 Pos Class Score  \n",
       "0                 0.47  \n",
       "1                 0.47  \n",
       "2                 0.53  \n",
       "3                 0.47  \n",
       "4                 0.53  \n",
       "5                 0.40  \n",
       "6                 0.51  \n",
       "7                 0.49  \n",
       "8                 0.52  \n",
       "9                 0.48  \n",
       "10                0.55  \n",
       "11                0.48  \n",
       "12                0.57  \n",
       "13                0.49  \n",
       "14                0.57  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results to the DataFrame containing all of the results:\n",
    "new_results = pd.DataFrame([{'Model': 'LGBM Model, Undersampled', 'Mean CV F1 Score': round(scores.mean(),2), 'F1 Pos Class Score':0.57}])\n",
    "results_df = pd.concat([results_df, new_results], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1946bb",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "185f1297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "{'learning_rate': 0.2, 'max_depth': 7, 'min_child_samples': 20, 'num_leaves': 31}\n",
      "0.8006962542460357\n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    'num_leaves': [31, 127],\n",
    "    'min_child_samples': [20, 30, 40],\n",
    "    'max_depth': [5, 6, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Initialize the classifier\n",
    "lgbm_model_os = LGBMClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lgbm_model_os, param_grid=grid, cv=5, scoring='f1', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_os, y_train_os)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e00274c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67507886 0.68125    0.82506527 0.91428571 0.90780142]\n",
      "Mean CV F1 score for the positive class: 0.80 (+/- 0.21)\n",
      "Test Classification Report, LGBM, Oversampled               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78       320\n",
      "           1       0.54      0.39      0.45       156\n",
      "\n",
      "    accuracy                           0.69       476\n",
      "   macro avg       0.64      0.61      0.62       476\n",
      "weighted avg       0.67      0.69      0.67       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# apply the tuned hyperparameters:\n",
    "\n",
    "lgbm_model_os_tuned= LGBMClassifier(num_leaves=31,min_child_samples=20,max_depth=7,learning_rate=0.2)\n",
    "\n",
    "# fit the model\n",
    "lgbm_model_os_tuned.fit(X_train_os, y_train_os)\n",
    "\n",
    "# make predictions for test data\n",
    "lgbm_y_pred_os_tuned = lgbm_model_os_tuned.predict(X_test)\n",
    "predictions = [round(value) for value in lgbm_y_pred_os_tuned]\n",
    "\n",
    "\n",
    "scores = cross_val_score(lgbm_model_os_tuned, X_train_os, y_train_os, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "\n",
    "print(\"Mean CV F1 score for the positive class: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print('Test Classification Report, LGBM, Oversampled',classification_report(y_test, lgbm_y_pred_os_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "83d2c17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[267  53]\n",
      " [ 95  61]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, lgbm_y_pred_os_tuned)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d6a92979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Undersampled Model</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression Oversampled, Tuned</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest, Oversampled, Tuned</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest, Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XG Boost, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XG Boost, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XG Boost, Oversampled, Tuned</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XG Boost, Undersampled, Tuned</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LGBM Model, Oversampled</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LGBM Model, Undersampled</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LGBM Model, Oversampled, tuned</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Model  Mean CV F1 Score  \\\n",
       "0            Logistic Regression Base Model              0.42   \n",
       "1     Logistic Regression Oversampled Model              0.69   \n",
       "2    Logistic Regression Undersampled Model              0.72   \n",
       "3    Logistic Regression Oversampled, Tuned              0.72   \n",
       "4   Logistic Regression Undersampled, Tuned              0.77   \n",
       "5                Random Forest, Oversampled              0.79   \n",
       "6               Random Forest, Undersampled              0.75   \n",
       "7         Random Forest, Oversampled, Tuned              0.81   \n",
       "8        Random Forest, Undersampled, Tuned              0.77   \n",
       "9                     XG Boost, Oversampled              0.79   \n",
       "10                   XG Boost, Undersampled              0.75   \n",
       "11             XG Boost, Oversampled, Tuned              0.79   \n",
       "12            XG Boost, Undersampled, Tuned              0.76   \n",
       "13                  LGBM Model, Oversampled              0.78   \n",
       "14                 LGBM Model, Undersampled              0.76   \n",
       "15           LGBM Model, Oversampled, tuned              0.80   \n",
       "\n",
       "    F1 Pos Class Score  \n",
       "0                 0.47  \n",
       "1                 0.47  \n",
       "2                 0.53  \n",
       "3                 0.47  \n",
       "4                 0.53  \n",
       "5                 0.40  \n",
       "6                 0.51  \n",
       "7                 0.49  \n",
       "8                 0.52  \n",
       "9                 0.48  \n",
       "10                0.55  \n",
       "11                0.48  \n",
       "12                0.57  \n",
       "13                0.49  \n",
       "14                0.57  \n",
       "15                0.45  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results to the DataFrame containing all of the results:\n",
    "new_results = pd.DataFrame([{'Model': 'LGBM Model, Oversampled, tuned', 'Mean CV F1 Score': round(scores.mean(),2), 'F1 Pos Class Score':0.45}])\n",
    "results_df = pd.concat([results_df, new_results], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd25326",
   "metadata": {},
   "source": [
    "<b>Undersampled</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "70d452d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "{'learning_rate': 0.2, 'max_depth': 7, 'min_child_samples': 20, 'num_leaves': 31}\n",
      "0.7612449110387799\n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    'num_leaves': [31, 127],\n",
    "    'min_child_samples': [20, 30, 40],\n",
    "    'max_depth': [5, 6, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Initialize the classifier\n",
    "lgbm_model_us = LGBMClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lgbm_model_us, param_grid=grid, cv=5, scoring='f1', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_us, y_train_us)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ddffcffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83529412 0.71604938 0.76300578 0.75757576 0.73429952]\n",
      "Mean CV F1 score for the positive class: 0.76 (+/- 0.08)\n",
      "Test Classification Report, LGBM, Undersampled               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.50      0.62       320\n",
      "           1       0.42      0.76      0.54       156\n",
      "\n",
      "    accuracy                           0.58       476\n",
      "   macro avg       0.62      0.63      0.58       476\n",
      "weighted avg       0.68      0.58      0.59       476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# apply the tuned hyperparameters:\n",
    "\n",
    "lgbm_model_us_tuned= LGBMClassifier(num_leaves=31,min_child_samples=20,max_depth=7,learning_rate=0.2)\n",
    "\n",
    "# fit the model\n",
    "lgbm_model_us_tuned.fit(X_train_us, y_train_us)\n",
    "\n",
    "# make predictions for test data\n",
    "lgbm_y_pred_us_tuned = lgbm_model_us_tuned.predict(X_test)\n",
    "predictions = [round(value) for value in lgbm_y_pred_us_tuned]\n",
    "\n",
    "\n",
    "scores = cross_val_score(lgbm_model_us_tuned, X_train_us, y_train_us, cv=5, scoring='f1')\n",
    "print(scores)\n",
    "\n",
    "print(\"Mean CV F1 score for the positive class: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print('Test Classification Report, LGBM, Undersampled',classification_report(y_test, lgbm_y_pred_us_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bf0b99d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[160 160]\n",
      " [ 38 118]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, lgbm_y_pred_us_tuned)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7c9f01a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Undersampled Model</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression Oversampled, Tuned</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest, Oversampled, Tuned</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest, Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XG Boost, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XG Boost, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XG Boost, Oversampled, Tuned</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XG Boost, Undersampled, Tuned</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LGBM Model, Oversampled</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LGBM Model, Undersampled</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LGBM Model, Oversampled, tuned</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LGBM Model, Undersampled, tuned</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Model  Mean CV F1 Score  \\\n",
       "0            Logistic Regression Base Model              0.42   \n",
       "1     Logistic Regression Oversampled Model              0.69   \n",
       "2    Logistic Regression Undersampled Model              0.72   \n",
       "3    Logistic Regression Oversampled, Tuned              0.72   \n",
       "4   Logistic Regression Undersampled, Tuned              0.77   \n",
       "5                Random Forest, Oversampled              0.79   \n",
       "6               Random Forest, Undersampled              0.75   \n",
       "7         Random Forest, Oversampled, Tuned              0.81   \n",
       "8        Random Forest, Undersampled, Tuned              0.77   \n",
       "9                     XG Boost, Oversampled              0.79   \n",
       "10                   XG Boost, Undersampled              0.75   \n",
       "11             XG Boost, Oversampled, Tuned              0.79   \n",
       "12            XG Boost, Undersampled, Tuned              0.76   \n",
       "13                  LGBM Model, Oversampled              0.78   \n",
       "14                 LGBM Model, Undersampled              0.76   \n",
       "15           LGBM Model, Oversampled, tuned              0.80   \n",
       "16          LGBM Model, Undersampled, tuned              0.76   \n",
       "\n",
       "    F1 Pos Class Score  \n",
       "0                 0.47  \n",
       "1                 0.47  \n",
       "2                 0.53  \n",
       "3                 0.47  \n",
       "4                 0.53  \n",
       "5                 0.40  \n",
       "6                 0.51  \n",
       "7                 0.49  \n",
       "8                 0.52  \n",
       "9                 0.48  \n",
       "10                0.55  \n",
       "11                0.48  \n",
       "12                0.57  \n",
       "13                0.49  \n",
       "14                0.57  \n",
       "15                0.45  \n",
       "16                0.54  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append the results to the DataFrame containing all of the results:\n",
    "new_results = pd.DataFrame([{'Model': 'LGBM Model, Undersampled, tuned', 'Mean CV F1 Score': round(scores.mean(),2), 'F1 Pos Class Score':0.54}])\n",
    "results_df = pd.concat([results_df, new_results], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfddc960",
   "metadata": {},
   "source": [
    "This is actually worse than when it was untuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "64c72203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LGBM Model, Oversampled, tuned</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression Oversampled, Tuned</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XG Boost, Oversampled, Tuned</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XG Boost, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LGBM Model, Oversampled</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest, Oversampled, Tuned</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest, Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Undersampled Model</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LGBM Model, Undersampled, tuned</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XG Boost, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XG Boost, Undersampled, Tuned</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LGBM Model, Undersampled</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Model  Mean CV F1 Score  \\\n",
       "5                Random Forest, Oversampled              0.79   \n",
       "15           LGBM Model, Oversampled, tuned              0.80   \n",
       "0            Logistic Regression Base Model              0.42   \n",
       "1     Logistic Regression Oversampled Model              0.69   \n",
       "3    Logistic Regression Oversampled, Tuned              0.72   \n",
       "11             XG Boost, Oversampled, Tuned              0.79   \n",
       "9                     XG Boost, Oversampled              0.79   \n",
       "13                  LGBM Model, Oversampled              0.78   \n",
       "7         Random Forest, Oversampled, Tuned              0.81   \n",
       "6               Random Forest, Undersampled              0.75   \n",
       "8        Random Forest, Undersampled, Tuned              0.77   \n",
       "4   Logistic Regression Undersampled, Tuned              0.77   \n",
       "2    Logistic Regression Undersampled Model              0.72   \n",
       "16          LGBM Model, Undersampled, tuned              0.76   \n",
       "10                   XG Boost, Undersampled              0.75   \n",
       "12            XG Boost, Undersampled, Tuned              0.76   \n",
       "14                 LGBM Model, Undersampled              0.76   \n",
       "\n",
       "    F1 Pos Class Score  \n",
       "5                 0.40  \n",
       "15                0.45  \n",
       "0                 0.47  \n",
       "1                 0.47  \n",
       "3                 0.47  \n",
       "11                0.48  \n",
       "9                 0.48  \n",
       "13                0.49  \n",
       "7                 0.49  \n",
       "6                 0.51  \n",
       "8                 0.52  \n",
       "4                 0.53  \n",
       "2                 0.53  \n",
       "16                0.54  \n",
       "10                0.55  \n",
       "12                0.57  \n",
       "14                0.57  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort results by F1 pos class score\n",
    "results_df.sort_values(by='F1 Pos Class Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "06b2f1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV F1 Score</th>\n",
       "      <th>F1 Pos Class Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Base Model</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression Oversampled Model</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression Undersampled Model</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression Oversampled, Tuned</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XG Boost, Undersampled</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LGBM Model, Undersampled</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XG Boost, Undersampled, Tuned</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LGBM Model, Undersampled, tuned</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest, Undersampled, Tuned</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LGBM Model, Oversampled</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XG Boost, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XG Boost, Oversampled, Tuned</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest, Oversampled</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LGBM Model, Oversampled, tuned</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest, Oversampled, Tuned</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Model  Mean CV F1 Score  \\\n",
       "0            Logistic Regression Base Model              0.42   \n",
       "1     Logistic Regression Oversampled Model              0.69   \n",
       "2    Logistic Regression Undersampled Model              0.72   \n",
       "3    Logistic Regression Oversampled, Tuned              0.72   \n",
       "6               Random Forest, Undersampled              0.75   \n",
       "10                   XG Boost, Undersampled              0.75   \n",
       "14                 LGBM Model, Undersampled              0.76   \n",
       "12            XG Boost, Undersampled, Tuned              0.76   \n",
       "16          LGBM Model, Undersampled, tuned              0.76   \n",
       "4   Logistic Regression Undersampled, Tuned              0.77   \n",
       "8        Random Forest, Undersampled, Tuned              0.77   \n",
       "13                  LGBM Model, Oversampled              0.78   \n",
       "9                     XG Boost, Oversampled              0.79   \n",
       "11             XG Boost, Oversampled, Tuned              0.79   \n",
       "5                Random Forest, Oversampled              0.79   \n",
       "15           LGBM Model, Oversampled, tuned              0.80   \n",
       "7         Random Forest, Oversampled, Tuned              0.81   \n",
       "\n",
       "    F1 Pos Class Score  \n",
       "0                 0.47  \n",
       "1                 0.47  \n",
       "2                 0.53  \n",
       "3                 0.47  \n",
       "6                 0.51  \n",
       "10                0.55  \n",
       "14                0.57  \n",
       "12                0.57  \n",
       "16                0.54  \n",
       "4                 0.53  \n",
       "8                 0.52  \n",
       "13                0.49  \n",
       "9                 0.48  \n",
       "11                0.48  \n",
       "5                 0.40  \n",
       "15                0.45  \n",
       "7                 0.49  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort results by mean CV F1 score\n",
    "results_df.sort_values(by='Mean CV F1 Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec092727",
   "metadata": {},
   "source": [
    "<b>CONCLUSION:</b>\n",
    "\n",
    "If we are looking at the F1 Positive Class Score, the XG Boost, Undersampled & Tuned, as well as the LGBM, Undersampled (not tuned) performed the best.\n",
    "\n",
    "If we are looking at the Mean CV F1 score, the Random Forest, Oversampled & Tuned performed the best, but it should be noted that the F1 Pos Class Score was much worse. \n",
    "\n",
    "When looking at all of the scoring data (classification reports & confusion matrix), overall I think that the XG Boost. Undersampled & Tuned, is the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5a439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
